{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fda6d9de-96de-41e7-b27d-0dd6367690fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dd3de8320c94f05b667fe1bf8111e95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IsADirectoryError",
     "evalue": "[Errno 21] Is a directory: 'coach420/2vkm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/dongwoo/anaconda3/envs/geo/lib/python3.7/concurrent/futures/process.py\", line 239, in _process_worker\n    r = call_item.fn(*call_item.args, **call_item.kwargs)\n  File \"/home/dongwoo/anaconda3/envs/geo/lib/python3.7/concurrent/futures/process.py\", line 198, in _process_chunk\n    return [fn(*args) for args in chunk]\n  File \"/home/dongwoo/anaconda3/envs/geo/lib/python3.7/concurrent/futures/process.py\", line 198, in <listcomp>\n    return [fn(*args) for args in chunk]\n  File \"/tmp/ipykernel_285262/801776002.py\", line 123, in get_features\n    with open(path, \"r\") as f:\nIsADirectoryError: [Errno 21] Is a directory: 'coach420/2vkm'\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_285262/801776002.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    364\u001b[0m     ds = ProteinDataset(\n\u001b[1;32m    365\u001b[0m         \u001b[0;34m\"./coach420\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m         \u001b[0mmax_res_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1500\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m     )\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_285262/801776002.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset_path, min_res_num, max_res_num, ss_constraints)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;31m# Load PDB files into dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mpaths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mstructures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_pdb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;31m# Remove None from self.structures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_285262/801776002.py\u001b[0m in \u001b[0;36mparse_pdb\u001b[0;34m(self, paths)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparse_pdb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Processing dataset of length {len(paths)}...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/geo/lib/python3.7/site-packages/tqdm/contrib/concurrent.py\u001b[0m in \u001b[0;36mprocess_map\u001b[0;34m(fn, *iterables, **tqdm_kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mtqdm_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mtqdm_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"lock_name\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"mp_lock\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_executor_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mProcessPoolExecutor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0miterables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtqdm_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/geo/lib/python3.7/site-packages/tqdm/contrib/concurrent.py\u001b[0m in \u001b[0;36m_executor_map\u001b[0;34m(PoolExecutor, fn, *iterables, **tqdm_kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mmap_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mPoolExecutor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mpool_kwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0miterables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmap_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/geo/lib/python3.7/site-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0mit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/geo/lib/python3.7/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1195\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1196\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/geo/lib/python3.7/concurrent/futures/process.py\u001b[0m in \u001b[0;36m_chain_from_iterable_of_lists\u001b[0;34m(iterable)\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0mcareful\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mto\u001b[0m \u001b[0mkeep\u001b[0m \u001b[0mreferences\u001b[0m \u001b[0mto\u001b[0m \u001b[0myielded\u001b[0m \u001b[0mobjects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m     \"\"\"\n\u001b[0;32m--> 483\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0melement\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    484\u001b[0m         \u001b[0melement\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/geo/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult_iterator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    596\u001b[0m                     \u001b[0;31m# Careful not to keep a reference to the popped future\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m                         \u001b[0;32myield\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/geo/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    426\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/geo/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: 'coach420/2vkm'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import math\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from pathlib import Path\n",
    "import logging\n",
    "import warnings\n",
    "from tqdm.contrib.concurrent import process_map\n",
    "import biotite.structure as struc\n",
    "from biotite.structure.io.pdb import PDBFile\n",
    "from torch.utils.data._utils.collate import default_collate\n",
    "\n",
    "non_standard_to_standard = {\n",
    "    '2AS':'ASP', '3AH':'HIS', '5HP':'GLU', 'ACL':'ARG', 'AGM':'ARG', 'AIB':'ALA', 'ALM':'ALA', 'ALO':'THR', 'ALY':'LYS', 'ARM':'ARG',\n",
    "    'ASA':'ASP', 'ASB':'ASP', 'ASK':'ASP', 'ASL':'ASP', 'ASQ':'ASP', 'ASX':'ASP', 'AYA':'ALA', 'BCS':'CYS', 'BHD':'ASP', 'BMT':'THR', 'BNN':'ALA', # Added ASX => ASP\n",
    "    'BUC':'CYS', 'BUG':'LEU', 'C5C':'CYS', 'C6C':'CYS', 'CAS':'CYS', 'CCS':'CYS', 'CEA':'CYS', 'CGU':'GLU', 'CHG':'ALA', 'CLE':'LEU', 'CME':'CYS',\n",
    "    'CSD':'ALA', 'CSO':'CYS', 'CSP':'CYS', 'CSS':'CYS', 'CSW':'CYS', 'CSX':'CYS', 'CXM':'MET', 'CY1':'CYS', 'CY3':'CYS', 'CYG':'CYS',\n",
    "    'CYM':'CYS', 'CYQ':'CYS', 'DAH':'PHE', 'DAL':'ALA', 'DAR':'ARG', 'DAS':'ASP', 'DCY':'CYS', 'DGL':'GLU', 'DGN':'GLN', 'DHA':'ALA',\n",
    "    'DHI':'HIS', 'DIL':'ILE', 'DIV':'VAL', 'DLE':'LEU', 'DLY':'LYS', 'DNP':'ALA', 'DPN':'PHE', 'DPR':'PRO', 'DSN':'SER', 'DSP':'ASP',\n",
    "    'DTH':'THR', 'DTR':'TRP', 'DTY':'TYR', 'DVA':'VAL', 'EFC':'CYS', 'FLA':'ALA', 'FME':'MET', 'GGL':'GLU', 'GL3':'GLY', 'GLZ':'GLY',\n",
    "    'GMA':'GLU', 'GSC':'GLY', 'HAC':'ALA', 'HAR':'ARG', 'HIC':'HIS', 'HIP':'HIS', 'HMR':'ARG', 'HPQ':'PHE', 'HTR':'TRP', 'HYP':'PRO',\n",
    "    'IAS':'ASP', 'IIL':'ILE', 'IYR':'TYR', 'KCX':'LYS', 'LLP':'LYS', 'LLY':'LYS', 'LTR':'TRP', 'LYM':'LYS', 'LYZ':'LYS', 'MAA':'ALA', 'MEN':'ASN',\n",
    "    'MHS':'HIS', 'MIS':'SER', 'MLE':'LEU', 'MPQ':'GLY', 'MSA':'GLY', 'MSE':'MET', 'MVA':'VAL', 'NEM':'HIS', 'NEP':'HIS', 'NLE':'LEU',\n",
    "    'NLN':'LEU', 'NLP':'LEU', 'NMC':'GLY', 'OAS':'SER', 'OCS':'CYS', 'OMT':'MET', 'PAQ':'TYR', 'PCA':'GLU', 'PEC':'CYS', 'PHI':'PHE',\n",
    "    'PHL':'PHE', 'PR3':'CYS', 'PRR':'ALA', 'PTR':'TYR', 'PYL':'LYS', 'PYX':'CYS', 'SAC':'SER', 'SAR':'GLY', 'SCH':'CYS', 'SCS':'CYS', 'SCY':'CYS', 'SEC':'CYS', # Added pyrrolysine and selenocysteine\n",
    "    'SEL':'SER', 'SEP':'SER', 'SET':'SER', 'SHC':'CYS', 'SHR':'LYS', 'SMC':'CYS', 'SOC':'CYS', 'STY':'TYR', 'SVA':'SER', 'TIH':'ALA',\n",
    "    'TPL':'TRP', 'TPO':'THR', 'TPQ':'ALA', 'TRG':'LYS', 'TRO':'TRP', 'TYB':'TYR', 'TYI':'TYR', 'TYQ':'TYR', 'TYS':'TYR', 'TYY':'TYR'\n",
    "}\n",
    "\n",
    "three_to_one_letter = {'CYS': 'C', 'ASP': 'D', 'SER': 'S', 'GLN': 'Q', 'LYS': 'K',\n",
    "    'ILE': 'I', 'PRO': 'P', 'THR': 'T', 'PHE': 'F', 'ASN': 'N',\n",
    "    'GLY': 'G', 'HIS': 'H', 'LEU': 'L', 'ARG': 'R', 'TRP': 'W',\n",
    "    'ALA': 'A', 'VAL':'V', 'GLU': 'E', 'TYR': 'Y', 'MET': 'M', 'UNK': 'X'}\n",
    "\n",
    "one_to_three_letter = {v:k for k,v in three_to_one_letter.items()}\n",
    "\n",
    "letter_to_num = {'C': 4, 'D': 3, 'S': 15, 'Q': 5, 'K': 11, 'I': 9,\n",
    "                       'P': 14, 'T': 16, 'F': 13, 'A': 0, 'G': 7, 'H': 8,\n",
    "                       'E': 6, 'L': 10, 'R': 1, 'W': 17, 'V': 19,\n",
    "                       'N': 2, 'Y': 18, 'M': 12, 'X': 20}\n",
    "\n",
    "class ProteinDataset(Dataset):\n",
    "    def __init__(self, dataset_path, min_res_num=40, max_res_num=256, ss_constraints=True):\n",
    "        super().__init__()\n",
    "        # Ignore biotite warnings\n",
    "        warnings.filterwarnings(\"ignore\", \".*elements were guessed from atom_.*\")\n",
    "\n",
    "        self.min_res_num = min_res_num\n",
    "        self.max_res_num = max_res_num\n",
    "        self.ss_constraints = ss_constraints\n",
    "\n",
    "        # Load PDB files into dataset\n",
    "        paths = list(Path(dataset_path).iterdir())\n",
    "        structures = self.parse_pdb(paths)\n",
    "\n",
    "        # Remove None from self.structures\n",
    "        self.structures = [self.to_tensor(i) for i in structures if i is not None]\n",
    "\n",
    "    def parse_pdb(self, paths):\n",
    "        logging.info(f\"Processing dataset of length {len(paths)}...\")\n",
    "        data = list(process_map(self.get_features, paths, chunksize=10))\n",
    "        return data\n",
    "\n",
    "    def get_coarse_constraints(self, model, cb, dist_threshold=7, dmax=20, block_dropout=0.1):\n",
    "        # Used for splitting block secondary structures\n",
    "        def consecutive(data, stepsize=1):\n",
    "            return np.split(data, np.where(np.diff(data) != stepsize)[0] + 1)\n",
    "\n",
    "        dist_threshold_norm = (dist_threshold / dmax * 2) - 1\n",
    "\n",
    "        psea_to_index = {\"a\": 1, \"b\": 2, \"c\": 3}\n",
    "        chain_id = struc.get_chains(model)[0]\n",
    "        s = [psea_to_index[i] for i in struc.annotate_sse(model, chain_id)]\n",
    "        if len(s) != cb.shape[0]: return None, None  # Shape mismatch from PSEA: TODO: Find issue\n",
    "        # annotate_sse is based on CA coordinates, so the shape is wrong if a CA coordinate is missing\n",
    "        # Fix by inserting 0 at indices where CA coordinates are missing\n",
    "        # ca_mask_index = (1-ca_atom_mask).nonzero()[0]\n",
    "        # [s.insert(i,0) for i in ca_mask_index]\n",
    "        s = np.array(s)\n",
    "\n",
    "        helix_mask = (s == 1)\n",
    "        beta_mask = (s == 2)\n",
    "\n",
    "        # Block adjacencies\n",
    "        helix_indices = helix_mask.nonzero()[0]\n",
    "        beta_indices = beta_mask.nonzero()[0]\n",
    "\n",
    "        helix_indices_split = [i for i in consecutive(helix_indices) if len(i) >= 4]\n",
    "        beta_indices_split = [i for i in consecutive(beta_indices) if len(i) >= 4]\n",
    "\n",
    "        helix_mask_pair = np.zeros(cb.shape)\n",
    "        for i in helix_indices_split:\n",
    "            start, end = i[0], i[-1]\n",
    "            helix_mask_pair[start:end, start:end] = 1\n",
    "\n",
    "        beta_mask_pair = np.zeros(cb.shape)\n",
    "        for i1 in beta_indices_split:\n",
    "            for i2 in beta_indices_split:\n",
    "                start1, end1 = i1[0], i1[-1]\n",
    "                start2, end2 = i2[0], i2[-1]\n",
    "                beta_mask_pair[start1:end1, start2:end2] = 1\n",
    "\n",
    "        helix_beta_indices = helix_indices_split + beta_indices_split\n",
    "\n",
    "        block_adj_mask = np.zeros(cb.shape)\n",
    "        for idx1, block1 in enumerate(helix_beta_indices):\n",
    "            for idx2, block2 in enumerate(helix_beta_indices):\n",
    "                if idx1 == idx2: continue\n",
    "                b1_start, b1_end = block1[0], block1[-1]\n",
    "                b2_start, b2_end = block2[0], block2[-1]\n",
    "                dist = cb[b1_start:b1_end, b2_start:b2_end].min()\n",
    "                if dist < dist_threshold_norm:\n",
    "                    block_adj_mask[b1_start:b1_end, b2_start:b2_end] = 1\n",
    "        constraints = np.stack([helix_mask_pair, beta_mask_pair, block_adj_mask], axis=-1)\n",
    "\n",
    "        # Convert to string for dataloader\n",
    "        helix_beta_str = ','.join([f\"{i[0]}:{i[-1]}\" for i in helix_beta_indices])\n",
    "        return constraints, helix_beta_str\n",
    "\n",
    "    def get_features(self, path):\n",
    "        with open(path, \"r\") as f:\n",
    "            structure = PDBFile.read(f)\n",
    "\n",
    "        if structure.get_model_count() > 1: return None\n",
    "        struct = structure.get_structure()\n",
    "        if struc.get_chain_count(struct) > 1: return None\n",
    "        _, aa = struc.get_residues(struct)\n",
    "\n",
    "        # Replace nonstandard amino acids\n",
    "        for idx,a in enumerate(aa):\n",
    "            if a not in three_to_one_letter.keys():\n",
    "                aa[idx] = non_standard_to_standard.get(a, \"UNK\")\n",
    "\n",
    "        one_letter_aa = [three_to_one_letter[i] for i in aa]\n",
    "        aa_str = ''.join(one_letter_aa)\n",
    "        aa = [letter_to_num[i] for i in one_letter_aa]\n",
    "        nres = len(aa)\n",
    "\n",
    "        if nres > self.max_res_num or nres < self.min_res_num: return None\n",
    "\n",
    "        mask = np.ones(nres)\n",
    "        atom_mask = np.ones((nres, 3))\n",
    "\n",
    "        bb_coords = []\n",
    "        for res_idx, res in enumerate(struc.residue_iter(struct)):\n",
    "            # Find backbone + CB atoms\n",
    "            atom_types = res.get_annotation(\"atom_name\")\n",
    "            all_coords = res.coord[0]\n",
    "            crd = []\n",
    "            for atom_idx, a in enumerate([\"N\", \"CA\", \"C\"]):\n",
    "                idx = np.where(atom_types == a)[0]\n",
    "                if idx.size == 0:\n",
    "                    atom_mask[res_idx, atom_idx] = 0\n",
    "                    # Rolling mask i-1 and i+1 since all 3 atoms are used for CB reconstruction\n",
    "                    mask[res_idx] = 0\n",
    "                    if res_idx != 0:\n",
    "                        mask[res_idx-1] = 0\n",
    "                    if res_idx != nres-1:\n",
    "                        mask[res_idx+1] = 0\n",
    "                    crd.append([0, 0, 0])\n",
    "                else:\n",
    "                    crd.append(all_coords[idx[0]])\n",
    "            bb_coords.append(crd)\n",
    "        bb_coords = np.array(bb_coords)\n",
    "\n",
    "        coords_6d = get_coords6d(bb_coords, dmax=20.0, normalize=True)\n",
    "        coords_6d = np.nan_to_num(coords_6d)\n",
    "        padding = np.ones((nres,nres)).reshape(nres,nres,1)\n",
    "\n",
    "        if self.ss_constraints:\n",
    "            block_adj, helix_beta_str = self.get_coarse_constraints(struct[0], coords_6d[:, :, 0], dist_threshold=5)\n",
    "            if block_adj is None: return None\n",
    "            coords_6d = np.concatenate([coords_6d,block_adj,padding],axis=-1)\n",
    "        else:\n",
    "            coords_6d = np.concatenate([coords_6d, padding], axis=-1)\n",
    "            helix_beta_str = []\n",
    "        mask_pair = mask.reshape(1,-1) * mask.reshape(-1, 1) # N, N\n",
    "\n",
    "        coords_6d = coords_6d * mask_pair.reshape(nres,nres,1) # N, N, C\n",
    "        coords_6d = coords_6d.transpose(2,0,1) # C, N, N\n",
    "\n",
    "        return {\n",
    "            \"id\": path.stem,\n",
    "            \"coords\": bb_coords,\n",
    "            \"coords_6d\": coords_6d,\n",
    "            \"aa\": aa,\n",
    "            \"aa_str\": aa_str,\n",
    "            \"mask_pair\": mask_pair,\n",
    "            \"ss_indices\": helix_beta_str # Used for block dropout\n",
    "        }\n",
    "\n",
    "    def to_tensor(self, d):\n",
    "        feat_dtypes = {\n",
    "            \"id\": None,\n",
    "            \"coords\": torch.float32,\n",
    "            \"coords_6d\": torch.float32,\n",
    "            \"aa\": torch.long,\n",
    "            \"aa_str\": None,\n",
    "            \"mask_pair\": torch.bool,\n",
    "            \"ss_indices\": None\n",
    "        }\n",
    "\n",
    "        for k,v in d.items():\n",
    "            if feat_dtypes[k] is not None:\n",
    "                d[k] = torch.tensor(v).to(dtype=feat_dtypes[k])\n",
    "\n",
    "        return d\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.structures)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.structures[idx]\n",
    "\n",
    "\n",
    "##### Functions below adapted from trRosetta https://github.com/RosettaCommons/trRosetta2/blob/main/trRosetta/coords6d.py\n",
    "# calculate dihedral angles defined by 4 sets of points\n",
    "def get_dihedrals(a, b, c, d):\n",
    "    \n",
    "    # Ignore divide by zero errors\n",
    "    np.seterr(divide='ignore', invalid='ignore')\n",
    "    \n",
    "    b0 = -1.0*(b - a)\n",
    "    b1 = c - b\n",
    "    b2 = d - c\n",
    "    \n",
    "    b1 /= np.linalg.norm(b1, axis=-1)[:,None]\n",
    "    v = b0 - np.sum(b0*b1, axis=-1)[:,None]*b1\n",
    "    w = b2 - np.sum(b2*b1, axis=-1)[:,None]*b1\n",
    "\n",
    "    x = np.sum(v*w, axis=-1)\n",
    "    y = np.sum(np.cross(b1, v)*w, axis=-1)\n",
    "\n",
    "    return np.arctan2(y, x)\n",
    "\n",
    "# calculate planar angles defined by 3 sets of points\n",
    "def get_angles(a, b, c):\n",
    "\n",
    "    v = a - b\n",
    "    v /= np.linalg.norm(v, axis=-1)[:,None]\n",
    "\n",
    "    w = c - b\n",
    "    w /= np.linalg.norm(w, axis=-1)[:,None]\n",
    "\n",
    "    x = np.sum(v*w, axis=1)\n",
    "\n",
    "    return np.arccos(x)\n",
    "\n",
    "# get 6d coordinates from x,y,z coords of N,Ca,C atoms\n",
    "def get_coords6d(xyz, dmax=20.0, normalize=True):\n",
    "\n",
    "    nres = xyz.shape[0]\n",
    "\n",
    "    # three anchor atoms\n",
    "    N  = xyz[:,0]\n",
    "    Ca = xyz[:,1]\n",
    "    C  = xyz[:,2]\n",
    "\n",
    "    # recreate Cb given N,Ca,C\n",
    "    b = Ca - N\n",
    "    c = C - Ca\n",
    "    a = np.cross(b, c)\n",
    "    Cb = -0.58273431*a + 0.56802827*b - 0.54067466*c + Ca\n",
    "\n",
    "    # fast neighbors search to collect all\n",
    "    # Cb-Cb pairs within dmax\n",
    "    kdCb = scipy.spatial.cKDTree(Cb)\n",
    "    indices = kdCb.query_ball_tree(kdCb, dmax)\n",
    "\n",
    "    # indices of contacting residues\n",
    "    idx = np.array([[i,j] for i in range(len(indices)) for j in indices[i] if i != j]).T\n",
    "    idx0 = idx[0]\n",
    "    idx1 = idx[1]\n",
    "\n",
    "    # Cb-Cb distance matrix\n",
    "    dist6d = np.full((nres, nres), dmax).astype(float)\n",
    "    dist6d[idx0,idx1] = np.linalg.norm(Cb[idx1]-Cb[idx0], axis=-1)\n",
    "\n",
    "    # matrix of Ca-Cb-Cb-Ca dihedrals\n",
    "    omega6d = np.zeros((nres, nres))\n",
    "    omega6d[idx0,idx1] = get_dihedrals(Ca[idx0], Cb[idx0], Cb[idx1], Ca[idx1])\n",
    "\n",
    "    # matrix of polar coord theta\n",
    "    theta6d = np.zeros((nres, nres))\n",
    "    theta6d[idx0,idx1] = get_dihedrals(N[idx0], Ca[idx0], Cb[idx0], Cb[idx1])\n",
    "\n",
    "    # matrix of polar coord phi\n",
    "    phi6d = np.zeros((nres, nres))\n",
    "    phi6d[idx0,idx1] = get_angles(Ca[idx0], Cb[idx0], Cb[idx1])\n",
    "    \n",
    "    # Normalize all features to [-1,1]\n",
    "    if normalize:\n",
    "        # [4A, 20A]\n",
    "        dist6d = (dist6d / dmax*2) - 1\n",
    "        # [-pi, pi]\n",
    "        omega6d = omega6d / math.pi\n",
    "        # [-pi, pi]\n",
    "        theta6d = theta6d / math.pi\n",
    "        # [0, pi]\n",
    "        phi6d = (phi6d / math.pi*2) - 1\n",
    "\n",
    "    coords_6d = np.stack([dist6d,omega6d,theta6d,phi6d],axis=-1)\n",
    "\n",
    "    return coords_6d\n",
    "\n",
    "class PaddingCollate(object):\n",
    "\n",
    "    def __init__(self, max_len=None):\n",
    "        super().__init__()\n",
    "        self.max_len = max_len\n",
    "\n",
    "    @staticmethod\n",
    "    def _pad_last(x, n, value=0):\n",
    "        if isinstance(x, torch.Tensor):\n",
    "            assert x.size(0) <= n\n",
    "            if x.size(0) == n:\n",
    "                return x\n",
    "\n",
    "            # Pairwise embeddings TODO: not very elegant\n",
    "            if len(x.shape) >= 2 and x.shape[-1] != 3 and x.shape[-1] == x.shape[-2]:\n",
    "                x = F.pad(x, (0,n-x.shape[-1],0,n-x.shape[-2]), value=value)\n",
    "                return x\n",
    "\n",
    "            pad_size = [n - x.size(0)] + list(x.shape[1:])\n",
    "            pad = torch.full(pad_size, fill_value=value).to(x)\n",
    "            return torch.cat([x, pad], dim=0)\n",
    "        elif isinstance(x, str):\n",
    "            pad = value * (n - len(x))\n",
    "            return x + pad\n",
    "        elif isinstance(x, list):\n",
    "            pad = [value] * (n - len(x))\n",
    "            return x + pad\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_value(k):\n",
    "        if k in [\"aa_str\"]:\n",
    "            return \"_\"\n",
    "        elif k == \"aa\":\n",
    "            return 21 # masking value\n",
    "        elif k in [\"id\",\"ss_indices\"]:\n",
    "            return ''\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def __call__(self, data_list):\n",
    "        max_length = self.max_len if self.max_len else max([len(data[\"aa\"]) for data in data_list])\n",
    "        data_list_padded = []\n",
    "        for data in data_list:\n",
    "            data_padded = {\n",
    "                k: self._pad_last(v, max_length, value=self._get_value(k)) for k,v in data.items()\n",
    "            }\n",
    "            data_list_padded.append(data_padded)\n",
    "        return default_collate(data_list_padded)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    ds = ProteinDataset(\n",
    "        \"./coach420\",\n",
    "        max_res_num = 1500\n",
    "    )\n",
    "\n",
    "    print(len(ds))\n",
    "\n",
    "    # for i in range(7):\n",
    "    #     plt.imshow(ds[-1][\"coords_6d\"][:,:,i].numpy())\n",
    "    #     plt.savefig(f\"test{i}.png\")\n",
    "    #\n",
    "    # dl = torch.utils.data.DataLoader(\n",
    "    #     ds,\n",
    "    #     batch_size=8,\n",
    "    #     collate_fn=PaddingCollate(max_len=128),\n",
    "    # )\n",
    "    #\n",
    "    # batch = next(iter(dl))\n",
    "    # print(batch[\"coords_6d\"].shape)\n",
    "    # print(batch[\"aa\"].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c077a65-4475-4d6e-a7ef-7c24b029a865",
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install -c conda-forge biotite\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf37778-9729-4a0e-b633-f19840c55f5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo3.7",
   "language": "python",
   "name": "geo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
